# FROM lightbend/spark:2.1.0-OpenShift-2.4.0-rh-2.12
# FROM ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.3-3.1.1
FROM gcr.io/spark-operator/spark:v3.1.1
USER root
RUN mkdir -p /usr/share/man/man1


# Older version of jre/jdk is required 
# https://stackoverflow.com/questions/63167261/apachespark-read-from-s3-exception-premature-end-of-content-length-delimited-me
# Download binary from oracle https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html
ADD jre-8u211-linux-x64.tar.gz /opt/oraclejre/

RUN apt-get update --allow-releaseinfo-change \
    && apt-get update \
    && apt-get install -y curl tini openssl --fix-missing \
#    && software-properties-common \
#    && apt-add-repository 'deb http://security.debian.org/debian-security stretch/updates main' \
#    && apt-get update \
#    && apt-get install openjdk-8-jdk -y
     && apt-get clean

# ENV JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64/jre"
# ENV JAVA_VERSION=1.8.0_322
# ENV PATH="/usr/lib/jvm/java-8-openjdk-amd64/jre/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
# Note java version 1.8.0_322 does not work

ENV JAVA_HOME="/opt/oraclejre/jre1.8.0_211"
ENV JAVA_VERSION=1.8.0_211
ENV PATH="/opt/oraclejre/jre1.8.0_211/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

RUN ["mkdir", "-p", "\/opt\/spark\/jars"]
RUN ["curl", "https:\/\/repo1.maven.org\/maven2\/io\/fabric8\/kubernetes-client\/4.4.2\/kubernetes-client-4.4.2.jar", "--output", "\/opt\/spark\/jars\/kubernetes-client-4.4.2.jar", "--silent"]
RUN ["curl", "https:\/\/repo1.maven.org\/maven2\/org\/apache\/hadoop\/hadoop-aws\/2.7.3\/hadoop-aws-2.7.3.jar", "--output", "\/opt\/spark\/jars\/hadoop-aws-2.7.3.jar", "--silent"]
RUN ["curl", "https:\/\/repo1.maven.org\/maven2\/com\/amazonaws\/aws-java-sdk\/1.7.4\/aws-java-sdk-1.7.4.jar", "--output", "\/opt\/spark\/jars\/aws-java-sdk-1.7.4.jar", "--silent"]

RUN ["mkdir", "-p", "\/opt\/spark\/cfpb\/hmda\/jars\/"]
ADD 0/hmda-reports.jar /opt/spark/cfpb/hmda/jars/hmda-spark-reporting.jar
# RUN useradd -rm -s /bin/bash -g root -u 1001 spark-operator
# USER spark-operator 